(window.webpackJsonp=window.webpackJsonp||[]).push([[197],{578:function(a,t,e){"use strict";e.r(t);var o=e(13),s=Object(o.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("p",[a._v("在hdfs中，分成很多 "),e("code",[a._v("块")]),a._v("，每块 "),e("code",[a._v("128M")]),a._v(" , 所有存储的文件都会被切割成若干块，并且有 "),e("code",[a._v("三份")]),a._v(" 用于备份，分布存储于不同的 "),e("code",[a._v("datanode")])]),a._v(" "),e("h1",{attrs:{id:"什么是-hdfs-客户端"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#什么是-hdfs-客户端"}},[a._v("#")]),a._v(" 什么是 hdfs 客户端")]),a._v(" "),e("p",[e("code",[a._v("hdfs客户端")]),a._v(" 顾名思义就是客户端， 像 hadoop 服务器段发起文件存储的请求，而客户端的所有依赖的文件和脚本也都封装在 Hadoop 安装包内\n例如：")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("hadoop  fs -put  /root/aaa.tar.gz  /root\n")])])]),e("p",[a._v("将文件 "),e("code",[a._v("aaa.tar.gz")]),a._v(" 存储到 "),e("code",[a._v("hdfs")]),a._v(" 的 "),e("code",[a._v("/root")]),a._v(" 目录，如果不写目录会报错")]),a._v(" "),e("h1",{attrs:{id:"常用的基本命令"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#常用的基本命令"}},[a._v("#")]),a._v(" 常用的基本命令")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("hadoop fs -rm [-r] 删除文件/文件夹\nhadoop fs -ls  查看目录\nhadoop fs -put  上传/存储文件\nhadoop fs -cat  如果是文本类型的数据可以直接查看\n")])])]),e("h1",{attrs:{id:"存储的原理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#存储的原理"}},[a._v("#")]),a._v(" 存储的原理")]),a._v(" "),e("ol",[e("li",[a._v("客户端找到 "),e("code",[a._v("core-site.xml")]),a._v(" 中的 "),e("code",[a._v("hdpnn0:9000")]),a._v(" ,向它发起请求")]),a._v(" "),e("li",[e("code",[a._v("namenode")]),a._v(" 接受请求，分配 "),e("code",[a._v("datanode")]),a._v(" ，并且保存文件的映射")]),a._v(" "),e("li",[a._v("文件被切割成若干块，存储到不同的 "),e("code",[a._v("datanode")]),a._v(" 中")]),a._v(" "),e("li",[a._v("读取文件时，namenode 根据映射读取文件块，返回客户端")])])])}),[],!1,null,null,null);t.default=s.exports}}]);